Gaps: "Gaps" is the idea that [[when transmitting a graph via smaller linearizations]], [[as the corpus gets larger, the chances of having incomplete information at any given point grows]], and [[even for information that is highly valued]], and [[Canopy helps by presenting information exhaustively]].

When transmitting a graph via smaller linearizations: If a person builds an understanding for example by reading many books and articles on the subject.

As the corpus gets larger, the chances of having incomplete information at any given point grows: If the domain is very large, there is a good chance that there are points that didn't make it into any of the particular books or articles read by the person.

Even for information that is highly valued: Even if someone is very interested in a subject, there is a good chance that there is basic information about something they would be very interested in hearing about that they happen to have never heard because it just never was relevant to include in any of the narrow books and articles they've happened to see on the topic.

Canopy helps by presenting information exhaustively: In Canopy, a topic's paragraph is an exhaustive list of all information in the graph about that topic, and so it is much harder for pieces of information to fall between the cracks, as opposed to someone who is constructing an understanding by reading various books and articles, none of which may be attempting to provide an exhaustive list.
